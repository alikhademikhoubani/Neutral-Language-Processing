{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain\n!pip install langchain-community\n!pip install -U langchain langchain-google-genai google-generativeai\n!pip install PyPDF2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:29:59.458754Z","iopub.execute_input":"2025-08-18T15:29:59.458936Z","iopub.status.idle":"2025-08-18T15:30:22.281913Z","shell.execute_reply.started":"2025-08-18T15:29:59.458917Z","shell.execute_reply":"2025-08-18T15:30:22.281199Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed packaging-24.2\nCollecting langchain-community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.66)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.1 langchain-community-0.3.27 pydantic-settings-2.10.1 python-dotenv-1.1.1\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nCollecting langchain\n  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nCollecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nCollecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\nINFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\nCollecting google-generativeai\n  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\nINFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\nInstalling collected packages: filetype, langchain-core, langchain-text-splitters, langchain, langchain-google-genai\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.66\n    Uninstalling langchain-core-0.3.66:\n      Successfully uninstalled langchain-core-0.3.66\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.8\n    Uninstalling langchain-text-splitters-0.3.8:\n      Successfully uninstalled langchain-text-splitters-0.3.8\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.26\n    Uninstalling langchain-0.3.26:\n      Successfully uninstalled langchain-0.3.26\nSuccessfully installed filetype-1.2.0 langchain-0.3.27 langchain-core-0.3.74 langchain-google-genai-2.0.10 langchain-text-splitters-0.3.9\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from langchain_google_genai import ChatGoogleGenerativeAI\nimport PyPDF2 as pdf\nfrom langchain.schema import (\nAIMessage,\nHumanMessage,\nSystemMessage\n)\nfrom langchain import FewShotPromptTemplate\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T16:34:25.957814Z","iopub.execute_input":"2025-08-18T16:34:25.958038Z","iopub.status.idle":"2025-08-18T16:34:25.974899Z","shell.execute_reply.started":"2025-08-18T16:34:25.958022Z","shell.execute_reply":"2025-08-18T16:34:25.974204Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"llm = ChatGoogleGenerativeAI(\n    model = \"gemini-2.5-pro\",\n    google_api_key = \"AIzaSyBVo-gzuNCdIAKhS9WlhuKRlTK9J2aLMdk\",\n    temperature = 0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:31:49.324630Z","iopub.execute_input":"2025-08-18T15:31:49.325204Z","iopub.status.idle":"2025-08-18T15:31:49.404510Z","shell.execute_reply.started":"2025-08-18T15:31:49.325167Z","shell.execute_reply":"2025-08-18T15:31:49.403800Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"text = \"\"\"\nمدل ترنسفورمر یک شبکه عصبی است که از محتوای داده‌های ترتیبی یاد گرفته و مطابق با آن، داده‌های جدیدی تولید می‌کند. در واقع، ترنسفورمر نوعی مدل هوش مصنوعی است که با تحلیل الگوهای موجود در داده‌های متنی، چگونگی نگارش متون به زبان انسان را یاد گرفته و نمونه‌های جدیدی تولید کند. از ترنسفورمرها به عنوان پیشرفته‌ترین مدل‌های NLP که از ساختار «رمزگذار-رمزگشا» (Encoder-decoder) پیروی می‌کنند یاد می‌شود. اما برخلاف ساختارهای مشابه که از «شبکه‌های عصبی بازگشتی» (RNN) برای استخراج اطلاعات ترتیبی استفاده می‌کنند، ترنسفورمرها فاقد قابلیت بازگشتی هستند. این ساختارها به‌گونه‌ای طراحی شده‌اند که بتوانند ورودی را با تحلیل ارتباط میان بخش‌های مختلف آن درک کنند. مدل‌های ترنسفورمر برای انجام این کار تنها بر نوعی تکنیک ریاضیاتی به نام مکانیزم «توجه» یا Attention متکی هستند.\nایده مدل‌های ترنسفورمر اولین بار در سال ۲۰۱۷ و در مقاله‌ای با عنوان Attention is All You Need از شرکت گوگل مطرح شد و از آن زمان به عنوان یکی از تاثیرگذارترین نوآوری‌های حوزه یادگیری ماشین شناخته می‌شود. این مفهوم پیشگامانه نه تنها یک پیشرفت نظری بوده بلکه به‌طور عملی و در بسته نرم‌افزاری Tensor2Tensor کتابخانه TensorFlow نیز پیاده‌سازی شده است. در ادامه گروه تحقیقاتی NLP دانشگاه هاروارد، راهنمایی برای پیاده‌سازی مقاله با استفاده از کتابخانه PyTorch در زبان برنامه‌نویسی پایتون ارائه داد.\nمدل معرفی شده را می‌توان سرآغاز توسعه مدل‌های زبانی بزرگ مانند BERT نامید. در سال ۲۰۱۸ این تحول و توسعه به نقطه عطفی در حوزه NLP تبدیل شده بود و سال ۲۰۲۰، محققان شرکت OpenAI مدل زبانی GPT-3 را معرفی کردند. کاربران همان هفته‌های اول، مدل GPT-3 را در زمینه‌های متنوعی مانند هنر، برنامه‌نویسی و موسیقی به چالش کشیدند. در سال ۲۰۲۱، پژوهشگران دانشگاه استنفورد در مقاله‌ای این نوآوری‌ها را «مدل‌های پایه» (Foundation Models) نام‌گذاری کردند که بیانگر نقش اساسی آن‌ها در بازتعریف مفهوم هوش مصنوعی است. تمرکز این پژوهش بر تشریح نقش مدل‌های ترنسفورمر در گسترش مرزهای هوش مصنوعی است که فرصت‌های تازه‌ای را در این حوزه به ارمغان آورده‌اند.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:32:20.621880Z","iopub.execute_input":"2025-08-18T15:32:20.622199Z","iopub.status.idle":"2025-08-18T15:32:20.627240Z","shell.execute_reply.started":"2025-08-18T15:32:20.622146Z","shell.execute_reply":"2025-08-18T15:32:20.626528Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"chat_message = [\n    SystemMessage(content = \"تو یک دستیار خبره در زمینه خلاصه سازی متون هستی. کار تو این است که متن دریافتی را خلاصه کنی.\"),\n    HumanMessage(content = f\"لطفا متن زیر را خلاصه کن:\\n{text}\")\n]\n\nresponse = llm(chat_message)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:56:15.635928Z","iopub.execute_input":"2025-08-18T15:56:15.636606Z","iopub.status.idle":"2025-08-18T15:56:33.830021Z","shell.execute_reply.started":"2025-08-18T15:56:15.636580Z","shell.execute_reply":"2025-08-18T15:56:33.829389Z"}},"outputs":[{"name":"stdout","text":"content='البته، در اینجا خلاصه متن ارائه شده است:\\n\\n**خلاصه**\\n\\nمدل ترنسفورمر یک معماری شبکه عصبی پیشرفته با ساختار «رمزگذار-رمزگشا» است که برای درک داده\\u200cهای ترتیبی (مانند متن) طراحی شده است. ویژگی کلیدی این مدل، جایگزینی شبکه\\u200cهای بازگشتی (RNN) با مکانیزم «توجه» (Attention) است که به آن امکان تحلیل ارتباط بین تمام بخش\\u200cهای ورودی را می\\u200cدهد.\\n\\nاین مدل اولین بار در سال ۲۰۱۷ توسط گوگل در مقاله\\u200cای با عنوان \"Attention is All You Need\" معرفی شد و به سرعت به یکی از تاثیرگذارترین نوآوری\\u200cها در یادگیری ماشین تبدیل گشت.\\n\\nترنسفورمرها سرآغاز توسعه «مدل\\u200cهای زبانی بزرگ» (LLM) مانند BERT و GPT-3 بودند و به دلیل نقش بنیادینشان در پیشرفت هوش مصنوعی، امروزه با عنوان «مدل\\u200cهای پایه» (Foundation Models) نیز شناخته می\\u200cشوند.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--b963106a-1920-493d-88d2-5591dc25653d-0' usage_metadata={'input_tokens': 587, 'output_tokens': 217, 'total_tokens': 2458, 'input_token_details': {'cache_read': 0}}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:58:26.291761Z","iopub.execute_input":"2025-08-18T15:58:26.292493Z","iopub.status.idle":"2025-08-18T15:58:26.296296Z","shell.execute_reply.started":"2025-08-18T15:58:26.292469Z","shell.execute_reply":"2025-08-18T15:58:26.295548Z"}},"outputs":[{"name":"stdout","text":"البته، در اینجا خلاصه متن ارائه شده است:\n\n**خلاصه**\n\nمدل ترنسفورمر یک معماری شبکه عصبی پیشرفته با ساختار «رمزگذار-رمزگشا» است که برای درک داده‌های ترتیبی (مانند متن) طراحی شده است. ویژگی کلیدی این مدل، جایگزینی شبکه‌های بازگشتی (RNN) با مکانیزم «توجه» (Attention) است که به آن امکان تحلیل ارتباط بین تمام بخش‌های ورودی را می‌دهد.\n\nاین مدل اولین بار در سال ۲۰۱۷ توسط گوگل در مقاله‌ای با عنوان \"Attention is All You Need\" معرفی شد و به سرعت به یکی از تاثیرگذارترین نوآوری‌ها در یادگیری ماشین تبدیل گشت.\n\nترنسفورمرها سرآغاز توسعه «مدل‌های زبانی بزرگ» (LLM) مانند BERT و GPT-3 بودند و به دلیل نقش بنیادینشان در پیشرفت هوش مصنوعی، امروزه با عنوان «مدل‌های پایه» (Foundation Models) نیز شناخته می‌شوند.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Few-Shot Prompting","metadata":{}},{"cell_type":"code","source":"chat_message = [\n    SystemMessage(content = \"مثال: متن: [متن]. خلاصه: [مثال خلاصه]\\nاکنون، متن داده شده را به مانند فرمت بالا خلاصه کن:\"),\n    HumanMessage(content = {f\"[{text}]\"})\n]\n\nresponse = llm(chat_message)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T16:09:05.401348Z","iopub.execute_input":"2025-08-18T16:09:05.402087Z","iopub.status.idle":"2025-08-18T16:09:21.591716Z","shell.execute_reply.started":"2025-08-18T16:09:05.402063Z","shell.execute_reply":"2025-08-18T16:09:21.590595Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T16:09:30.549107Z","iopub.execute_input":"2025-08-18T16:09:30.549757Z","iopub.status.idle":"2025-08-18T16:09:30.553839Z","shell.execute_reply.started":"2025-08-18T16:09:30.549731Z","shell.execute_reply":"2025-08-18T16:09:30.553183Z"}},"outputs":[{"name":"stdout","text":"متن: [مدل ترنسفورمر یک شبکه عصبی است که از محتوای داده‌های ترتیبی یاد گرفته و مطابق با آن، داده‌های جدیدی تولید می‌کند. در واقع، ترنسفورمر نوعی مدل هوش مصنوعی است که با تحلیل الگوهای موجود در داده‌های متنی، چگونگی نگارش متون به زبان انسان را یاد گرفته و نمونه‌های جدیدی تولید کند. از ترنسفورمرها به عنوان پیشرفته‌ترین مدل‌های NLP که از ساختار «رمزگذار-رمزگشا» (Encoder-decoder) پیروی می‌کنند یاد می‌شود. اما برخلاف ساختارهای مشابه که از «شبکه‌های عصبی بازگشتی» (RNN) برای استخراج اطلاعات ترتیبی استفاده می‌کنند، ترنسفورمرها فاقد قابلیت بازگشتی هستند. این ساختارها به‌گونه‌ای طراحی شده‌اند که بتوانند ورودی را با تحلیل ارتباط میان بخش‌های مختلف آن درک کنند. مدل‌های ترنسفورمر برای انجام این کار تنها بر نوعی تکنیک ریاضیاتی به نام مکانیزم «توجه» یا Attention متکی هستند.\nایده مدل‌های ترنسفورمر اولین بار در سال ۲۰۱۷ و در مقاله‌ای با عنوان Attention is All You Need از شرکت گوگل مطرح شد و از آن زمان به عنوان یکی از تاثیرگذارترین نوآوری‌های حوزه یادگیری ماشین شناخته می‌شود. این مفهوم پیشگامانه نه تنها یک پیشرفت نظری بوده بلکه به‌طور عملی و در بسته نرم‌افزاری Tensor2Tensor کتابخانه TensorFlow نیز پیاده‌سازی شده است. در ادامه گروه تحقیقاتی NLP دانشگاه هاروارد، راهنمایی برای پیاده‌سازی مقاله با استفاده از کتابخانه PyTorch در زبان برنامه‌نویسی پایتون ارائه داد.\nمدل معرفی شده را می‌توان سرآغاز توسعه مدل‌های زبانی بزرگ مانند BERT نامید. در سال ۲۰۱۸ این تحول و توسعه به نقطه عطفی در حوزه NLP تبدیل شده بود و سال ۲۰۲۰، محققان شرکت OpenAI مدل زبانی GPT-3 را معرفی کردند. کاربران همان هفته‌های اول، مدل GPT-3 را در زمینه‌های متنوعی مانند هنر، برنامه‌نویسی و موسیقی به چالش کشیدند. در سال ۲۰۲۱، پژوهشگران دانشگاه استنفورد در مقاله‌ای این نوآوری‌ها را «مدل‌های پایه» (Foundation Models) نام‌گذاری کردند که بیانگر نقش اساسی آن‌ها در بازتعریف مفهوم هوش مصنوعی است. تمرکز این پژوهش بر تشریح نقش مدل‌های ترنسفورمر در گسترش مرزهای هوش مصنوعی است که فرصت‌های تازه‌ای را در این حوزه به ارمغان آورده‌اند.]. خلاصه: [مدل ترنسفورمر یک شبکه عصبی پیشرفته در حوزه NLP است که اولین بار در سال ۲۰۱۷ توسط گوگل معرفی شد. این مدل برخلاف ساختارهای قدیمی‌تر مانند RNN، تنها بر مکانیزم \"توجه\" (Attention) برای درک داده‌های ترتیبی تکیه می‌کند. این نوآوری، پایه‌گذار مدل‌های زبانی بزرگی مانند BERT و GPT-3 بوده و به دلیل نقش بنیادین خود در هوش مصنوعی مدرن، \"مدل پایه\" (Foundation Model) نامیده می‌شود.]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"examples = [\n    {\"text\": \"متن اصلی\",\n    \"summarized_text\": \"متن خلاصه شده\"}\n]\n\nexample_prompt = PromptTemplate(\n    template = \"\"\"متن اصلی: [{text}]\n    متن خلاصه شده: [{summarized_text}]\n    \"\"\",\n    input_variables = [\"text\", \"summarized_text\"]\n)\n\nfew_shot_template = FewShotPromptTemplate(\n    examples = examples,\n    example_prompt = example_prompt,\n    prefix = \"بر اساس مثال ارائه شده، خلاصه متن اصلی را تولید کن:\\n\",\n    suffix = \"متن اصلی: [{input}]\\nمتن خلاصه شده:\",\n    input_variables = [\"input\"],\n    example_separator = \"\\n\"\n)\nformatted_prompt = few_shot_template.format(input = text)\nresponse = llm.invoke(formatted_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T16:43:06.841212Z","iopub.execute_input":"2025-08-18T16:43:06.841494Z","iopub.status.idle":"2025-08-18T16:43:25.587099Z","shell.execute_reply.started":"2025-08-18T16:43:06.841473Z","shell.execute_reply":"2025-08-18T16:43:25.586546Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T16:43:28.439781Z","iopub.execute_input":"2025-08-18T16:43:28.440039Z","iopub.status.idle":"2025-08-18T16:43:28.444318Z","shell.execute_reply.started":"2025-08-18T16:43:28.440020Z","shell.execute_reply":"2025-08-18T16:43:28.443623Z"}},"outputs":[{"name":"stdout","text":"[\nمدل ترنسفورمر، یک معماری شبکه عصبی پیشرفته در حوزه پردازش زبان طبیعی (NLP) است که برای درک و تولید داده‌های ترتیبی مانند متن به کار می‌رود. این مدل، برخلاف ساختارهای قدیمی‌تر مبتنی بر شبکه‌های بازگشتی (RNN)، فاقد قابلیت بازگشتی بوده و برای تحلیل ارتباط میان بخش‌های مختلف ورودی، تنها بر مکانیزم «توجه» (Attention) تکیه می‌کند.\n\nاین معماری اولین بار در سال ۲۰۱۷ توسط گوگل در مقاله‌ای با عنوان «Attention is All You Need» معرفی شد و به سرعت به یکی از تاثیرگذارترین نوآوری‌ها در یادگیری ماشین تبدیل گشت. توسعه ترنسفورمرها زمینه‌ساز ظهور «مدل‌های زبانی بزرگ» (LLMs) مانند BERT و GPT-3 شد که امروزه به عنوان «مدل‌های پایه» (Foundation Models) شناخته می‌شوند و نقشی اساسی در گسترش مرزهای هوش مصنوعی ایفا می‌کنند.\n]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# Role-Specific Prompting","metadata":{}},{"cell_type":"code","source":"chat_message = [\n    SystemMessage(content = \"خلاصه ای از متن ارائه شده را برای مخاطبانی از مدیران بیمارستان ارائه دهید.\"),\n    HumanMessage(content = f\"متن ارائه شده: {text}\")\n]\n\nresponse = llm(chat_message)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:01:51.835384Z","iopub.execute_input":"2025-08-18T17:01:51.835650Z","iopub.status.idle":"2025-08-18T17:02:19.220241Z","shell.execute_reply.started":"2025-08-18T17:01:51.835630Z","shell.execute_reply":"2025-08-18T17:02:19.219655Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:02:22.150050Z","iopub.execute_input":"2025-08-18T17:02:22.150386Z","iopub.status.idle":"2025-08-18T17:02:22.154517Z","shell.execute_reply.started":"2025-08-18T17:02:22.150366Z","shell.execute_reply":"2025-08-18T17:02:22.153896Z"}},"outputs":[{"name":"stdout","text":"بسیار عالی. در ادامه خلاصه‌ای از متن ارائه شده، ویژه مدیران بیمارستان، با تمرکز بر کاربردها و اهمیت استراتژیک آن ارائه می‌شود:\n\n---\n\n### **خلاصه مدیریتی: آشنایی با فناوری هوش مصنوعی \"ترنسفورمر\" و اهمیت آن برای مراکز درمانی**\n\n**موضوع اصلی:**\nمدل \"ترنسفورمر\" یک فناوری پیشرفته هوش مصنوعی است که در درک، تحلیل و تولید متون پیچیده مشابه انسان، انقلابی ایجاد کرده است. این همان فناوری است که در ابزارهای معروفی مانند ChatGPT (مبتنی بر مدل GPT) به کار رفته است.\n\n**چرا این فناوری برای مدیران بیمارستان اهمیت دارد؟**\nبیمارستان‌ها با حجم عظیمی از داده‌های متنی (پرونده‌های الکترونیک سلامت، گزارش‌های پزشکی، یادداشت‌های پرستاری، مقالات تحقیقاتی و مکاتبات اداری) سروکار دارند. فناوری ترنسفورمر می‌تواند این داده‌ها را به یک دارایی استراتژیک تبدیل کند.\n\n**قابلیت‌های کلیدی این فناوری:**\n\n1.  **درک عمیق از زمینه (Context):** برخلاف مدل‌های قدیمی‌تر، ترنسفورمرها می‌توانند روابط بین کلمات و عبارات را در یک متن طولانی درک کنند. این ویژگی برای تحلیل دقیق پرونده‌های پزشکی که جزئیات در آن‌ها اهمیت حیاتی دارد، بسیار ارزشمند است.\n2.  **خلاصه‌سازی هوشمند:** این مدل‌ها می‌توانند سوابق طولانی پزشکی بیمار یا مقالات تحقیقاتی پیچیده را در چند پاراگراف کلیدی خلاصه کنند و در زمان پزشکان و کادر درمان صرفه‌جویی کنند.\n3.  **تولید متن:** می‌توانند به صورت خودکار پیش‌نویس گزارش‌های پزشکی، خلاصه‌ پرونده‌های ترخیص یا پاسخ به سوالات متداول بیماران را تهیه کنند و بار کاری تیم اداری و درمانی را کاهش دهند.\n\n**کاربردهای بالقوه در محیط بیمارستان:**\n\n*   **بهبود تصمیم‌گیری بالینی:** تحلیل سریع و هوشمندانه کلیه سوابق یک بیمار برای یافتن الگوها یا هشدارهای پنهان.\n*   **افزایش بهره‌وری:** خودکارسازی فرآیندهای مستندسازی و گزارش‌نویسی.\n*   **استخراج داده‌های ارزشمند:** شناسایی روندها و الگوها از هزاران گزارش پزشکی برای تحقیقات یا بهبود فرآیندهای مدیریتی.\n*   **ارتقاء ارتباط با بیمار:** ایجاد سیستم‌های هوشمند برای پاسخگویی به سوالات بیماران و ارائه اطلاعات اولیه.\n\n**نکته پایانی:**\nفناوری ترنسفورمر صرفاً یک پیشرفت فنی نیست، بلکه یک \"مدل پایه\" برای نسل جدید هوش مصنوعی است. آشنایی با این فناوری و بررسی پتانسیل‌های آن، گامی اساسی برای مدرن‌سازی، افزایش کارایی و ارتقاء کیفیت خدمات در بیمارستان‌های پیشرو محسوب می‌شود.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# Step-by-Step (Chain-of-Thought) Prompting","metadata":{}},{"cell_type":"code","source":"chat_message = [\n    SystemMessage(content = \"نکات کلیدی متن ارائه شده را گام به گام بررسی کنید و اهمیت هر نکته را توضیح دهید. سپس، کل متن را در دو جمله خلاصه کنید.\"),\n    HumanMessage(content = f\"متن ارائه شده: {text}\")\n]\n\nresponse = llm(chat_message)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:06:45.371348Z","iopub.execute_input":"2025-08-18T17:06:45.371627Z","iopub.status.idle":"2025-08-18T17:07:13.954991Z","shell.execute_reply.started":"2025-08-18T17:06:45.371604Z","shell.execute_reply":"2025-08-18T17:07:13.954433Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:07:26.740617Z","iopub.execute_input":"2025-08-18T17:07:26.740899Z","iopub.status.idle":"2025-08-18T17:07:26.745501Z","shell.execute_reply.started":"2025-08-18T17:07:26.740878Z","shell.execute_reply":"2025-08-18T17:07:26.744647Z"}},"outputs":[{"name":"stdout","text":"عالی. بیایید متن را به صورت گام به گام تحلیل کرده و سپس خلاصه کنیم.\n\n### **بررسی گام به گام نکات کلیدی و اهمیت آن‌ها**\n\n**گام اول: تعریف و کارکرد اصلی مدل ترنسفورمر**\n\n*   **نکته کلیدی:** ترنسفورمر یک شبکه عصبی با ساختار «رمزگذار-رمزگشا» (Encoder-Decoder) است که برای یادگیری از داده‌های ترتیبی (مانند متن) و تولید داده‌های جدید طراحی شده است.\n*   **اهمیت:** این نکته، هویت اصلی مدل را مشخص می‌کند. به ما می‌گوید که ترنسفورمر یک ابزار هوش مصنوعی برای کار با داده‌هایی است که ترتیب در آن‌ها مهم است (مثل کلمات در یک جمله) و هدف آن درک و تولید چنین داده‌هایی است.\n\n**گام دوم: تمایز اصلی با مدل‌های قدیمی**\n\n*   **نکته کلیدی:** برخلاف مدل‌های قدیمی‌تر مانند «شبکه‌های عصبی بازگشتی» (RNN)، ترنسفورمرها فاقد قابلیت بازگشتی هستند و به جای آن، تنها بر مکانیزم «توجه» (Attention) تکیه می‌کنند.\n*   **اهمیت:** این مهم‌ترین نوآوری فنی ترنسفورمر است. حذف ساختار بازگشتی (که داده‌ها را کلمه به کلمه و به ترتیب پردازش می‌کرد) و جایگزینی آن با مکانیزم توجه، به مدل اجازه داد تا تمام کلمات ورودی را به صورت همزمان ببیند و ارتباط مستقیم بین کلمات دور از هم را بهتر درک کند. این تغییر باعث افزایش سرعت پردازش و بهبود درک متون طولانی شد.\n\n**گام سوم: نقطه شروع و تاریخچه**\n\n*   **نکته کلیدی:** ایده ترنسفورمر اولین بار در سال ۲۰۱۷ توسط گوگل در مقاله‌ای با عنوان «Attention is All You Need» مطرح و به صورت عملی پیاده‌سازی شد.\n*   **اهمیت:** این نکته به ما یک مبدأ تاریخی مشخص می‌دهد و نشان می‌دهد که این فناوری چقدر جدید است. نام مقاله («توجه تمام آن چیزی است که نیاز دارید») نیز بر اهمیت محوری مکانیزم Attention به عنوان جایگزینی کامل برای ساختارهای قدیمی تأکید می‌کند.\n\n**گام چهارم: تأثیر و میراث**\n\n*   **نکته کلیدی:** ترنسفورمر سرآغاز توسعه «مدل‌های زبانی بزرگ» (LLMs) مانند BERT و GPT-3 شد.\n*   **اهمیت:** این نکته نشان می‌دهد که ترنسفورمر فقط یک مدل تئوری موفق نبود، بلکه به سنگ بنای اصلی برای ساخت قدرتمندترین ابزارهای هوش مصنوعی امروزی تبدیل شد. تمام مدل‌های زبانی پیشرفته‌ای که امروز می‌شناسیم، بر پایه همین معماری ساخته شده‌اند.\n\n**گام پنجم: جایگاه فعلی و چشم‌انداز آینده**\n\n*   **نکته کلیدی:** این مدل‌ها اکنون به عنوان «مدل‌های پایه» (Foundation Models) شناخته می‌شوند که نقش اساسی در بازتعریف هوش مصنوعی و گسترش مرزهای آن دارند.\n*   **اهمیت:** این مفهوم نشان‌دهنده تغییر نگرش به این مدل‌هاست. آن‌ها دیگر فقط برای یک کار خاص (مانند ترجمه) نیستند، بلکه زیرساختی بنیادی محسوب می‌شوند که می‌توان انواع برنامه‌های کاربردی هوشمند (از تولید محتوا تا برنامه‌نویسی) را بر اساس آن‌ها ساخت.\n\n---\n\n### **خلاصه کل متن در دو جمله**\n\nمدل ترنسفورمر یک معماری شبکه عصبی است که در سال ۲۰۱۷ با جایگزین کردن ساختارهای بازگشتی با مکانیزم «توجه» (Attention)، انقلابی در پردازش زبان طبیعی ایجاد کرد. این نوآوری به سنگ بنای توسعه مدل‌های زبانی بزرگ مدرن مانند GPT و BERT تبدیل شد و اکنون به عنوان یک «مدل پایه» اساسی، مرزهای هوش مصنوعی را گسترش می‌دهد.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Instruction-Heavy Prompting","metadata":{}},{"cell_type":"code","source":"chat_message = [\n    SystemMessage(content = \"متن ارائه شده را دقیقا در 50 کلمه خلاصه کنید. از نکات برجسته استفاده کنید و از نقل قول مستقیم خودداری کنید.\"),\n    HumanMessage(content = f\"متن ارائه شده: {text}\")\n]\n\nresponse = llm(chat_message)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:18:32.035202Z","iopub.execute_input":"2025-08-18T17:18:32.035476Z","iopub.status.idle":"2025-08-18T17:18:52.082385Z","shell.execute_reply.started":"2025-08-18T17:18:32.035455Z","shell.execute_reply":"2025-08-18T17:18:52.081601Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T17:18:54.314142Z","iopub.execute_input":"2025-08-18T17:18:54.314828Z","iopub.status.idle":"2025-08-18T17:18:54.318612Z","shell.execute_reply.started":"2025-08-18T17:18:54.314803Z","shell.execute_reply":"2025-08-18T17:18:54.317816Z"}},"outputs":[{"name":"stdout","text":"*   مدل ترنسفورمر یک شبکه عصبی با ساختار رمزگذار-رمزگشا برای تحلیل داده‌های ترتیبی است.\n*   این مدل برخلاف شبکه‌های بازگشتی (RNN)، تنها با مکانیزم «توجه» (Attention) ارتباطات داخلی داده را درک می‌کند.\n*   این نوآوری که در سال ۲۰۱۷ توسط گوگل معرفی شد، پایه اصلی مدل‌های زبانی بزرگ است.\n","output_type":"stream"}],"execution_count":41}]}