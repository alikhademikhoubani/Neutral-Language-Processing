{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12797393,"sourceType":"datasetVersion","datasetId":8091127}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U langchain langchain-google-genai google-generativeai\n!pip install langchain-community\n!pip install pymupdf --upgrade","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:47:20.602573Z","iopub.execute_input":"2025-08-18T12:47:20.602836Z","iopub.status.idle":"2025-08-18T12:47:46.808014Z","shell.execute_reply.started":"2025-08-18T12:47:20.602769Z","shell.execute_reply":"2025-08-18T12:47:46.807008Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nCollecting langchain\n  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nCollecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nCollecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\nINFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\nCollecting google-generativeai\n  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\nINFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\nInstalling collected packages: filetype, langchain-core, langchain-text-splitters, langchain, langchain-google-genai\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.66\n    Uninstalling langchain-core-0.3.66:\n      Successfully uninstalled langchain-core-0.3.66\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.8\n    Uninstalling langchain-text-splitters-0.3.8:\n      Successfully uninstalled langchain-text-splitters-0.3.8\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.26\n    Uninstalling langchain-0.3.26:\n      Successfully uninstalled langchain-0.3.26\nSuccessfully installed filetype-1.2.0 langchain-0.3.27 langchain-core-0.3.74 langchain-google-genai-2.0.10 langchain-text-splitters-0.3.9\nCollecting langchain-community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.74)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.1 langchain-community-0.3.27 pydantic-settings-2.10.1 python-dotenv-1.1.1\nCollecting pymupdf\n  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.26.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:50:07.752964Z","iopub.execute_input":"2025-08-18T12:50:07.753322Z","iopub.status.idle":"2025-08-18T12:50:14.618735Z","shell.execute_reply.started":"2025-08-18T12:50:07.753297Z","shell.execute_reply":"2025-08-18T12:50:14.617486Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.12.0\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from langchain_google_genai import ChatGoogleGenerativeAI\nimport fitz  \nfrom transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom langchain.chat_models import init_chat_model\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.messages import HumanMessage\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\nimport base64\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import FAISS\nfrom langchain.docstore.document import Document\nimport io","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:47:58.258299Z","iopub.execute_input":"2025-08-18T12:47:58.258663Z","iopub.status.idle":"2025-08-18T12:48:32.328920Z","shell.execute_reply.started":"2025-08-18T12:47:58.258617Z","shell.execute_reply":"2025-08-18T12:48:32.327946Z"}},"outputs":[{"name":"stderr","text":"2025-08-18 12:48:15.582450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755521295.826309      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755521295.902908      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"llm = ChatGoogleGenerativeAI(\n    model = \"gemini-2.0-flash\",\n    google_api_key = \"AIzaSyBVo-gzuNCdIAKhS9WlhuKRlTK9J2aLMdk\",\n    temperature = 0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:48:42.680528Z","iopub.execute_input":"2025-08-18T12:48:42.681720Z","iopub.status.idle":"2025-08-18T12:48:42.777199Z","shell.execute_reply.started":"2025-08-18T12:48:42.681682Z","shell.execute_reply":"2025-08-18T12:48:42.776332Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:48:44.220073Z","iopub.execute_input":"2025-08-18T12:48:44.220417Z","iopub.status.idle":"2025-08-18T12:48:51.839652Z","shell.execute_reply.started":"2025-08-18T12:48:44.220393Z","shell.execute_reply":"2025-08-18T12:48:51.838530Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54adb51d88814e82bb9766364abbf4b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8912283a2801451ba3ba88444821b43e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73fc0666025432d97cb0a36c5caa039"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"203f34b376004751a38d0e7f6ff9cc54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d043f4cf63c64050a21409a60f1e8c93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abc706cf61e42b1802eea90d64b10f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c3ad16c2b11491da06ce2e11059583a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a1e22624a2649c781a45c4586410d40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"835e911085fe42bc9a04f78a1e388440"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def embed_image(image_data):\n    if isinstance(image_data, str):  #If path\n        image = Image.open(image_data).convert(\"RGB\")\n    else:  #If PIL Image\n        image = image_data\n\n    inputs = clip_processor(images = image, return_tensors = \"pt\")\n    with torch.no_grad():\n        features = clip_model.get_image_features(**inputs)\n        features = features / features.norm(dim = -1, keepdim = True)\n        return features.squeeze().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:39.332203Z","iopub.execute_input":"2025-08-18T12:49:39.332563Z","iopub.status.idle":"2025-08-18T12:49:39.338748Z","shell.execute_reply.started":"2025-08-18T12:49:39.332538Z","shell.execute_reply":"2025-08-18T12:49:39.337824Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def embed_text(text):\n    inputs = clip_processor(\n        text = text,\n        return_tensors = \"pt\",\n        padding = True,\n        truncation = True,\n        max_length = 77  #CLIP's max token length\n    )\n    with torch.no_grad():\n        features = clip_model.get_text_features(**inputs)\n        features = features / features.norm(dim = -1, keepdim = True)\n        return features.squeeze().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:41.155902Z","iopub.execute_input":"2025-08-18T12:49:41.156282Z","iopub.status.idle":"2025-08-18T12:49:41.161942Z","shell.execute_reply.started":"2025-08-18T12:49:41.156257Z","shell.execute_reply":"2025-08-18T12:49:41.160975Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/multimodalexample/multimodal_sample.pdf\"\ndoc = fitz.open(pdf_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:42.916790Z","iopub.execute_input":"2025-08-18T12:49:42.919316Z","iopub.status.idle":"2025-08-18T12:49:42.960526Z","shell.execute_reply.started":"2025-08-18T12:49:42.919258Z","shell.execute_reply":"2025-08-18T12:49:42.959438Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"all_docs = []\nall_embeddings = []\nimage_data_store = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:44.712952Z","iopub.execute_input":"2025-08-18T12:49:44.713432Z","iopub.status.idle":"2025-08-18T12:49:44.718671Z","shell.execute_reply.started":"2025-08-18T12:49:44.713395Z","shell.execute_reply":"2025-08-18T12:49:44.717771Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 500,\n    chunk_overlap = 100\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:45.354478Z","iopub.execute_input":"2025-08-18T12:49:45.354931Z","iopub.status.idle":"2025-08-18T12:49:45.360689Z","shell.execute_reply.started":"2025-08-18T12:49:45.354897Z","shell.execute_reply":"2025-08-18T12:49:45.359867Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for i, page in enumerate(doc):\n    text = page.get_text()\n    if text.strip():\n        temp_doc = Document(page_content = text, metadata = {\"page\": i, \"type\": \"text\"})\n        text_chunks = splitter.split_documents([temp_doc])\n        for chunk in text_chunks:\n            embedding = embed_text(chunk.page_content)\n            all_embeddings.append(embedding)\n            all_docs.append(chunk)\n\n\n    \n    for img_index, img in enumerate(page.get_images(full = True)):\n        try:\n            xref = img[0]\n            base_image = doc.extract_image(xref)\n            image_bytes = base_image[\"image\"]\n    \n            pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n    \n            image_id = f\"page_{i}_img_{img_index}\"\n    \n            buffered = io.BytesIO()\n            pil_image.save(buffered, format = \"PNG\")\n            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n            image_data_store[image_id] = img_base64\n    \n            embedding = embed_image(pil_image)\n            all_embeddings.append(embedding)\n    \n            image_doc = Document(\n                page_content = f\"[Image: {image_id}]\",\n                metadata = {\"page\": i, \"type\": \"image\", \"image_id\": image_id}\n            )\n            all_docs.append(image_doc)\n    \n        except Exception as e:\n            print(f\"Error processing image {img_index} on page {i}: {e}\")\n            continue\n\ndoc.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:49:47.016271Z","iopub.execute_input":"2025-08-18T12:49:47.016666Z","iopub.status.idle":"2025-08-18T12:49:47.815693Z","shell.execute_reply.started":"2025-08-18T12:49:47.016633Z","shell.execute_reply":"2025-08-18T12:49:47.815008Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"embeddings_array = np.array(all_embeddings)\nvector_store = FAISS.from_embeddings(\n    text_embeddings = [(doc.page_content, emb) for doc, emb in zip(all_docs, embeddings_array)],\n    embedding = None,\n    metadatas = [doc.metadata for doc in all_docs]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:50:21.516294Z","iopub.execute_input":"2025-08-18T12:50:21.516637Z","iopub.status.idle":"2025-08-18T12:50:21.584656Z","shell.execute_reply.started":"2025-08-18T12:50:21.516610Z","shell.execute_reply":"2025-08-18T12:50:21.583968Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def retrieve_multimodal(query, k = 5):\n    query_embedding = embed_text(query)\n    results = vector_store.similarity_search_by_vector(\n        embedding = query_embedding,\n        k = k\n    )\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T12:55:18.105332Z","iopub.execute_input":"2025-08-18T12:55:18.106823Z","iopub.status.idle":"2025-08-18T12:55:18.112016Z","shell.execute_reply.started":"2025-08-18T12:55:18.106750Z","shell.execute_reply":"2025-08-18T12:55:18.111129Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_multimodal_message(query, retrieved_docs):\n    content = []\n    content.append({\n        \"type\": \"text\",\n        \"text\": f\"Question: {query}\\n\\nContext:\\n\"\n    })\n\n    text_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"text\"]\n    image_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"image\"]\n\n    if text_docs:\n        text_content = \"\\n\\n\".join([\n            f\"[Page {doc.metadata['page']}]: {doc.page_content}\"\n            for doc in text_docs\n        ])\n        content.append({\n            \"type\": \"text\",\n            \"text\": f\"Text excerpts:\\n{text_content}\\n\"\n        })\n\n    for doc in image_docs:\n        image_id = doc.metadata.get(\"image_id\")\n        if image_id and image_id in image_data_store:\n            content.append({\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": f\"data:image/png;base64,{image_data_store[image_id]}\"\n                }\n            })\n\n    content.append({\n        \"type\": \"text\",\n        \"text\": \"\\n\\nPlease answer the question based on the provided text and images.\"\n    })\n\n    return HumanMessage(content = content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:30:02.192197Z","iopub.execute_input":"2025-08-18T13:30:02.192911Z","iopub.status.idle":"2025-08-18T13:30:02.203378Z","shell.execute_reply.started":"2025-08-18T13:30:02.192868Z","shell.execute_reply":"2025-08-18T13:30:02.202072Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def multimodal_pdf_rag_pipeline(query):\n    context_docs = retrieve_multimodal(query, k = 5)\n    message = create_multimodal_message(query, context_docs)\n    response = llm.invoke([message])\n    print(f\"\\nRetrieved {len(context_docs)} documents:\")\n    for doc in context_docs:\n        doc_type = doc.metadata.get(\"type\", \"unknown\")\n        page = doc.metadata.get(\"page\", \"?\")\n        if doc_type == \"text\":\n            preview = doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content\n            print(f\" - Text from page {page}: {preview}\")\n        else:\n            print(f\" - Image from page {page}\")\n    print(\"\\n\")\n    return response.content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:30:07.619577Z","iopub.execute_input":"2025-08-18T13:30:07.620030Z","iopub.status.idle":"2025-08-18T13:30:07.627389Z","shell.execute_reply.started":"2025-08-18T13:30:07.619998Z","shell.execute_reply":"2025-08-18T13:30:07.626201Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    queries = [\n        \"What does the chart on page 1 show about revenue trends?\",\n        \"Summarize the main findings from the document\",\n        \"What visual elements are present in the document?\"\n    ]\n\n    for query in queries:\n        print(f\"\\nQuery: {query}\")\n        print(\"-\" * 50)\n        answer = multimodal_pdf_rag_pipeline(query)\n        print(f\"Answer: {answer}\")\n        print(\"=\" * 70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T13:30:09.805109Z","iopub.execute_input":"2025-08-18T13:30:09.805516Z","iopub.status.idle":"2025-08-18T13:30:15.269096Z","shell.execute_reply.started":"2025-08-18T13:30:09.805487Z","shell.execute_reply":"2025-08-18T13:30:15.268045Z"}},"outputs":[{"name":"stdout","text":"\nQuery: What does the chart on page 1 show about revenue trends?\n--------------------------------------------------\n\nRetrieved 2 documents:\n - Text from page 0: Annual Revenue Overview\nThis document summarizes the revenue trends across Q1, Q2, and Q3. As illust...\n - Image from page 0\n\n\nAnswer: The chart on page 0 shows that revenue grew steadily with the highest growth recorded in Q3.\n======================================================================\n\nQuery: Summarize the main findings from the document\n--------------------------------------------------\n\nRetrieved 2 documents:\n - Text from page 0: Annual Revenue Overview\nThis document summarizes the revenue trends across Q1, Q2, and Q3. As illust...\n - Image from page 0\n\n\nAnswer: The document summarizes revenue trends across Q1, Q2, and Q3. Revenue grew steadily, with the highest growth recorded in Q3. Q1 showed a moderate increase due to new product lines, Q2 outperformed Q1 due to marketing campaigns, and Q3 had exponential growth due to global expansion.\n======================================================================\n\nQuery: What visual elements are present in the document?\n--------------------------------------------------\n\nRetrieved 2 documents:\n - Text from page 0: Annual Revenue Overview\nThis document summarizes the revenue trends across Q1, Q2, and Q3. As illust...\n - Image from page 0\n\n\nAnswer: The document contains a bar chart with three bars. The first bar is blue, the second is green, and the third is red. The bars increase in height from left to right.\n======================================================================\n","output_type":"stream"}],"execution_count":21}]}