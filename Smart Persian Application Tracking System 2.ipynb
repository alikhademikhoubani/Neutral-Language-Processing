{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOU5bOQmmHTy",
        "outputId": "deb2cf94-6779-417c-da46-a2a952dc3993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.179.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.10\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.14)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-google-genai google-generativeai\n",
        "!pip install PyPDF2\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import PyPDF2 as pdf\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "pYm5vSgdmMmA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-pro\",\n",
        "    google_api_key = \"AIzaSyBVo-gzuNCdIAKhS9WlhuKRlTK9J2aLMdk\",\n",
        "    temperature = 0\n",
        ")"
      ],
      "metadata": {
        "id": "inxXSUC6mgNx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_pdf_text(uploaded_file_path):\n",
        "    with open(uploaded_file_path, \"rb\") as file:\n",
        "        reader = pdf.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            extracted = page.extract_text()\n",
        "            if extracted:\n",
        "                text += extracted\n",
        "        return text"
      ],
      "metadata": {
        "id": "8YqINC9-wIHX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/resume_pdf.pdf\""
      ],
      "metadata": {
        "id": "Nz7_NtJGnpup"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input_pdf_text(pdf_path)"
      ],
      "metadata": {
        "id": "EyGOOjecnyZw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4qUqvg_vGDJ",
        "outputId": "4ff7182d-fba8-493a-fc1f-70e063d004e0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "رزومه کاری \n",
            "نام و نام خانوادگی: علی خادمی  \n",
            "تاریخ تولد:  1376 (27 ساله) \n",
            "محل سکونت: تهران، ایران  \n",
            "رشته تخصصی: مهندسی کامپیوتر – گرایش معماری سیستمهای کامپیوتری \n",
            "ایمیل: [ ایمیل خود را وارد کنید] \n",
            "شماره تماس: [ شماره خود را وارد کنید] \n",
            "LinkedIn / GitHub:  [ لینکها را وارد کنید ] \n",
            "تحصیالت \n",
            "• کارشناسی ارشد  (M.Sc.)  – مهندسی کامپیوتر، گرایش معماری سیستمهای کامپیوتر ی  \n",
            "دانشگاه شهید بهشتی | 1400 –  1402 \n",
            "• کارشناسی  (B.Sc.)  – مهندسی نرمافزار \n",
            "دانشگاه آزاد اسالمی، واحد  تهران شمال | 1395 – 1400 \n",
            "مهارتها  \n",
            "مهارتهای برنامه نویسی \n",
            "• Python  \n",
            "هوش مصنوعی و یادگیری ماشین \n",
            "• الگوریتم های کالسیک یادگیری ماشین  (SVM, Random Forest, KNN, Regression) \n",
            "• یادگیری عمیق  (CNN, LSTM, RNN, MLP) \n",
            "• فاینتیون مدل های زبانی بزرگ  (LLMs) \n",
            "•  تکنیکهای  RAG  با استفاده از  LangChain \n",
            "کتابخانهها و ابزارها  \n",
            "• PyTorch, TensorFlow, Keras \n",
            "• Scikit -learn  \n",
            "• Hugging Face Transformers \n",
            "• LangChain \n",
            "• OpenAI API \n",
            "• Pandas, NumPy, Matplotlib سایر مهارتها  \n",
            "• طراحی و پیادهسازی سیستم های نرمافزاری   \n",
            "• تحلیل و معماری سیس\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\"\n",
        "شرح شغل و وظایف\n",
        "یک فرصت همکاری منحصربه‌فرد برای متخصصین هوش مصنوعی!\n",
        "ما به‌دنبال جذب متخصصی توانمند در حوزه AI هستیم که تجربه طراحی و پیاده‌سازی چت‌بات‌های هوشمند با محوریت منابع انسانی (HR) و ایمنی، بهداشت و محیط زیست (HSE) در محیط‌های صنعتی مانند پتروشیمی را داشته باشد.\n",
        "📌 وظایف و مسئولیت‌ها:\n",
        "توسعه چت‌بات‌های هوشمند برای پاسخ‌گویی به سوالات رایج منابع انسانی و HSE (مانند مقررات ایمنی، رویه‌های اضطراری، پرسش‌های پرسنلی و ...)\n",
        "پیاده‌سازی تعاملات کاربرپسند و دقیق، مطابق با الزامات محیط‌های صنعتی\n",
        "همکاری با تیم فنی و مدیریتی برای تحلیل نیازها و ارائه راه‌حل‌های هوشمند\n",
        "شرکت در جلسات هماهنگی (این جلسات جزو زمان کاری محاسبه نمی‌شوند)\n",
        "مستندسازی و ارائه گزارش‌های فنی در طول پروژه\n",
        "⏱ شرایط همکاری:\n",
        "حداکثر زمان کاری: 100 ساعت در ماه\n",
        "جلسات تیمی الزامی بوده و خارج از زمان کاری محسوب می‌شوند\n",
        "نوع همکاری: پاره‌وقت / پروژه‌ای\n",
        "پرداختی: ساعتی /پروژه ای\n",
        "دستمزد توافقی و متناسب با مهارت و سابقه شما\n",
        "🎯 مهارت‌های کلیدی:\n",
        "تسلط به توسعه چت‌بات با استفاده از ابزارهایی مانند Rasa، Dialogflow، Botpress، یا Microsoft Bot Framework\n",
        "آشنایی با مدل‌های زبان بزرگ (LLMs) و توانایی fine-tune یا استفاده از API آن‌ها (مانند GPT)\n",
        "تسلط به مفاهیم NLP و طراحی مکالمات چندلایه\n",
        "آشنایی با استانداردهای HSE در صنایع پتروشیمی و محیط‌های پرخطر، مزیت مهم محسوب می‌شود\n",
        "توانایی کار تیمی و تحلیل نیازهای کسب‌وکار در فضای صنعتی\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tNqrgMenpUrW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt = \"\"\"\n",
        "سلام. تو یک دستیار بسیار ماهر و با تجربه سیستم ردیابی کارجویان (ATS) هستی که درک عمیقی از حوزه فناوری، مهندسی نرم افزار، علوم داده و تحلیل داده دارد.\n",
        "    وظیفه تو ارزیابی رزومه بر اساس شرح شغل ارائه شده است.\n",
        "    در نظر داشته باش که بازار کار بسیار رقابتی است و باید بهترین کمک را برای بهبود رزومه ارائه بدی.\n",
        "    درصد تطبیق رزومه با شرح شغل ارائه شده و کلمات کلیدی گم شده در رزومه را بر اساس شرح شغل ارائه شده را با دقت بالا مشخص کن.\n",
        "    همچنین، رزومه ارائه شده را بر اساس شرح شغل ارائه شده، تجزیه و تحلیل کن و خلاصه این تجزیه و تحلیل را مشخص کن.\n",
        "    رزومه: {text},\n",
        "    شرح شغل: {job_description}\n",
        "    من پاسخ را مشابه ساختار زیر می خواهم:\n",
        "    [\n",
        "    میزان درصد تطبیق رزومه با شرح شغل:\n",
        "    کلمات کلیدی گم شده در رزومه بر اساس شرح شغل:\n",
        "    خلاصه تجزیه و تحلیل رزومه بر اساس شرح شغل:\n",
        "    ]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PvrSNJ9juvVI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    template = input_prompt,\n",
        "    input_variables = [\"text\", \"job_description\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Wn0zAJ27pWTd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "cGKzOJ7Dtlq2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run({\"text\": text, \"job_description\": job_description})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipy3QY9Ut0NE",
        "outputId": "455d18a1-9843-4d24-a757-f6b725d596bb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عالی. به عنوان یک دستیار متخصص ATS با درک عمیق از حوزه فناوری، رزومه و شرح شغل ارائه شده را با دقت تحلیل می‌کنم.\n",
            "\n",
            "[\n",
            "**میزان درصد تطبیق رزومه با شرح شغل:** **70%**\n",
            "\n",
            "**توضیح درصد:** این رزومه از نظر فنی و پایه‌ای بسیار قوی است و با هسته اصلی تکنولوژی‌های مورد نیاز شغل (LLM, RAG, NLP) همخوانی بالایی دارد. با این حال، عدم اشاره مستقیم به ابزارهای ساخت چت‌بات و دانش تخصصی حوزه صنعت (HR و HSE) باعث کاهش درصد تطبیق شده است. این درصد نشان‌دهنده پتانسیل بالای کارجو برای موفقیت در این موقعیت شغلی است، به شرطی که بتواند این شکاف‌ها را در مصاحبه یا با ویرایش رزومه پوشش دهد.\n",
            "\n",
            "---\n",
            "\n",
            "**کلمات کلیدی گم شده در رزومه بر اساس شرح شغل:**\n",
            "\n",
            "*   **ابزارهای تخصصی چت‌بات:**\n",
            "    *   Chatbot (چت‌بات)\n",
            "    *   Rasa\n",
            "    *   Dialogflow\n",
            "    *   Botpress\n",
            "    *   Microsoft Bot Framework\n",
            "*   **حوزه تخصصی کسب‌وکار:**\n",
            "    *   منابع انسانی (HR)\n",
            "    *   ایمنی، بهداشت و محیط زیست (HSE)\n",
            "    *   صنعتی (Industrial)\n",
            "    *   پتروشیمی (Petrochemical)\n",
            "*   **مفاهیم کاربردی:**\n",
            "    *   طراحی مکالمات (Conversation Design)\n",
            "    *   تحلیل نیازهای کسب‌وکار (Business Needs Analysis)\n",
            "    *   کاربرپسند (User-friendly)\n",
            "\n",
            "---\n",
            "\n",
            "**خلاصه تجزیه و تحلیل رزومه بر اساس شرح شغل:**\n",
            "\n",
            "این رزومه متعلق به یک متخصص هوش مصنوعی با بنیه فنی بسیار قوی و مرتبط با فناوری‌های زیرساختی مورد نیاز این موقعیت شغلی است. با این حال، رزومه به صورت عمومی و آکادمیک نوشته شده و برای این شرح شغل خاص، بهینه‌سازی نشده است.\n",
            "\n",
            "**نقاط قوت کلیدی:**\n",
            "\n",
            "1.  **تسلط بر LLM و RAG:** تجربه عملی در فاین‌تیون کردن مدل‌های زبانی بزرگ (LLM Fine-tuning) و پیاده‌سازی سیستم‌های پرسش و پاسخ با استفاده از RAG و LangChain، دقیقاً همان تکنولوژی محوری است که برای ساخت چت‌بات‌های هوشمند مدرن نیاز است. این مهم‌ترین نقطه قوت رزومه شماست.\n",
            "2.  **تجربه در NLP:** سابقه کار با مدل‌های CNN و LSTM در حوزه پردازش زبان طبیعی، درک عمیق شما از مفاهیم پایه NLP را نشان می‌دهد که برای طراحی مکالمات پیچیده ضروری است.\n",
            "3.  **مهارت در ابزارهای پایه:** تسلط بر کتابخانه‌هایی مانند PyTorch, Hugging Face Transformers و OpenAI API نشان می‌دهد که شما توانایی کار با جدیدترین ابزارهای حوزه AI را دارید.\n",
            "\n",
            "**نقاط قابل بهبود و شکاف‌ها:**\n",
            "\n",
            "1.  **عدم اشاره به پلتفرم‌های چت‌بات:** شرح شغل به وضوح به ابزارهایی مانند Rasa, Dialogflow و Botpress اشاره کرده است. رزومه شما هیچ اشاره‌ای به تجربه کار با این پلتفرم‌ها یا حتی آشنایی با آن‌ها ندارد. این بزرگترین شکاف رزومه شماست.\n",
            "2.  **فقدان دانش دامنه (Domain Knowledge):** موقعیت شغلی به شدت بر حوزه‌های منابع انسانی (HR) و ایمنی (HSE) در محیط صنعتی (پتروشیمی) متمرکز است. رزومه شما کاملاً عمومی است و هیچ نشانه‌ای از آشنایی یا علاقه به این حوزه‌ها را بروز نمی‌دهد. این موضوع می‌تواند باعث شود کارفرما شما را یک کاندیدای عمومی در نظر بگیرد و نه یک متخصص برای حل مشکلات خاص آن‌ها.\n",
            "3.  **تمرکز بر تحقیق به جای محصول:** زبان رزومه (مثلاً \"علایق پژوهشی\"، \"پروژه‌های شاخص\") بیشتر به سمت تحقیق و توسعه گرایش دارد. در حالی که شرح شغل به دنبال فردی برای \"پیاده‌سازی تعاملات کاربرپسند\" و \"تحلیل نیازهای کسب‌وکار\" است که نشان‌دهنده نیاز به یک ذهنیت محصول‌محور (Product-oriented) است.\n",
            "\n",
            "**توصیه‌های کلیدی برای بهبود:**\n",
            "\n",
            "1.  **اضافه کردن بخش \"خلاصه\" (Summary):** در ابتدای رزومه، یک پاراگراف خلاصه اضافه کنید و در آن مستقیماً به علاقه و توانایی خود برای \"طراحی و توسعه چت‌بات‌های هوشمند با استفاده از LLMها برای بهبود فرآیندهای صنعتی در حوزه‌های HR و HSE\" اشاره کنید.\n",
            "2.  **بازنویسی عناوین پروژه‌ها:** پروژه \"پیاده‌سازی RAG با LangChain\" را به این صورت بازنویسی کنید: \"**ساخت سامانه پرسش‌وپاسخ هوشمند (Intelligent Q&A System)** با ترکیب جستجوی برداری و مدل‌های زبانی (LLM) جهت پاسخگویی دقیق به سوالات کاربران\" این عنوان مستقیماً به عملکرد یک چت‌بات اشاره دارد.\n",
            "3.  **ایجاد بخش مهارت‌های مرتبط با چت‌بات:** حتی اگر با Rasa یا Dialogflow کار نکرده‌اید، می‌توانید در بخش مهارت‌ها، یک زیربخش با عنوان \"توسعه سیستم‌های محاوره‌ای (Conversational AI)\" ایجاد کرده و مهارت‌هایی مانند LangChain, RAG, LLM Fine-tuning و NLP را در آن قرار دهید تا ارتباط آن‌ها با ساخت چت‌بات مشخص‌تر شود.\n",
            "4.  **پوشش دانش دامنه:** اگر کوچکترین آشنایی با محیط‌های صنعتی، مقررات ایمنی یا فرآیندهای منابع انسانی دارید، حتماً به آن اشاره کنید. در غیر این صورت، در کاورلتر (Cover Letter) یا مصاحبه، اشتیاق خود را برای یادگیری سریع این حوزه‌ها و کاربرد هوش مصنوعی در آن‌ها نشان دهید.\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}