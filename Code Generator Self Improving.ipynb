{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cb5fe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from typing import TypedDict\n",
    "import json \n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ef97bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    query: str \n",
    "    answer: str \n",
    "    feedback: str \n",
    "    attempt_count: int\n",
    "    solved: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de5d8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongTermMemory:\n",
    "    def __init__(self, filepath = \"agent_memory10.json\"):\n",
    "        self.filepath = filepath \n",
    "        if not os.path.exists(filepath):\n",
    "            with open(filepath, \"w\", encoding = 'utf-8') as f:\n",
    "                json.dump([], f)\n",
    "\n",
    "    def load_lessons(self):\n",
    "        with open(self.filepath, \"r\", encoding = 'utf-8') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def save_lesson(self, lesson):\n",
    "        lessons = self.load_lessons()\n",
    "        if lesson not in lessons:\n",
    "            with open(self.filepath, \"w\", encoding = 'utf-8') as f:\n",
    "                json.dump(lessons, f, ensure_ascii = False, indent = 2)\n",
    "            print(f\"New lesson is saved in long term memory: {lesson}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9e5078aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_system = LongTermMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "29109f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_generator_node(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    attempt_count = state[\"attempt_count\"]\n",
    "\n",
    "    past_lessons = memory_system.load_lessons()\n",
    "    \n",
    "    sys_msg = \"\"\"\n",
    "    you are a professional python coding assistant experienced in python coding professionally based on the user query.\n",
    "    \"\"\" \n",
    "\n",
    "    hmn_msg = f\"\"\"\n",
    "    Write a python code for user query:\n",
    "    user_query: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    if past_lessons:\n",
    "        hmn_msg += \"\\nRules and lessons you learned from past experiences (consider them for generating the code:\\n)\"\n",
    "        for lesson in past_lessons:\n",
    "            hmn_msg += f\"- {lesson}\\n\"\n",
    "\n",
    "    if feedback:\n",
    "        hmn_msg += f\"Your last try in this task faced with this problems: {feedback}\\ngenerate an improved code.\"\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = \"codellama\",\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    message = [\n",
    "        SystemMessage(content = sys_msg),\n",
    "        HumanMessage(content = hmn_msg)\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(message).content \n",
    "\n",
    "    print(f\"Code Number {attempt_count}:\\n{response}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"attempt_count\": attempt_count + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validator_node(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    answer = state[\"answer\"]\n",
    "    attempt_count = state[\"attempt_count\"]\n",
    "    \n",
    "    print(f\"\\n---Try number: {attempt_count} ---\")\n",
    "\n",
    "    feedback = \"\"\n",
    "    solved = False \n",
    "\n",
    "    sys_msg = \"\"\"\n",
    "    You are a professional python code validator based on the query. \n",
    "    validate if the code corresponds to the query or not. give an integer score between 0 to 100. 0 means code absolutely not corresponds to the query and 100 means absolutely corresponds to the query.\n",
    "    corresponding to the query means that when the code is running, satisfy the user query without any error.\n",
    "    your output should just an integer score between 0 to 100. avoid any explaination. \n",
    "    \"\"\"\n",
    "\n",
    "    hmn_msg = f\"\"\"\n",
    "    validate the code based on the user query:\n",
    "\n",
    "    user_query: {query}\n",
    "\n",
    "    code: {answer}\n",
    "\n",
    "    just give an integer score between 0 to 100 without any explaination.\n",
    "    \"\"\"\n",
    "\n",
    "    message = [\n",
    "        SystemMessage(content = sys_msg),\n",
    "        HumanMessage(content = hmn_msg)\n",
    "    ]\n",
    "\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = \"codellama\",\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(message).content\n",
    "    print(response)\n",
    "\n",
    "    llm2 = ChatOllama(\n",
    "        model = \"llama3\",\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    pr = f\"\"\"\n",
    "    a code validator has gave a report and score between 0 to 100 to the python code. \n",
    "    just output an integer score that code has been gave. avoid any explanation.  \n",
    "\n",
    "    report: {response} \n",
    "    \"\"\"\n",
    "\n",
    "    response2 = llm2.invoke(pr).content\n",
    "\n",
    "    score = ast.literal_eval(response2)\n",
    "    print(f\"score: {score}\")\n",
    "\n",
    "    try:\n",
    "        if score < 80:\n",
    "            prompt = \"\"\"\n",
    "            You are a professional debugger python code assistant. \n",
    "            the python code that is wrote based on the query {query} has got {score} score from 100 for how much corresponds to the query.\n",
    "            check and analysis the code has wrote and determine why the code has got {score} score from 100.\n",
    "            then specify which part of code should change to get higher score and more accurate code based on the query.\n",
    "            \"\"\"\n",
    "\n",
    "            response2 = llm.invoke(prompt).content \n",
    "            \n",
    "            raise ValueError(f\"The code is not accurately corresponds to the query. The code that you has wrote has this problems: {response2}\")\n",
    "\n",
    "        print(\"Success! The code is highly corresponds to the user query.\")\n",
    "        solved = True\n",
    "\n",
    "    except Exception as e:\n",
    "        feedback = str(e)\n",
    "\n",
    "    return {\n",
    "        \"solved\": solved,\n",
    "        \"feedback\": feedback\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc68866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflector_node(state: AgentState):\n",
    "    feedback = state[\"feedback\"]\n",
    "    query = state[\"query\"]\n",
    "    answer = state[\"answer\"]\n",
    "\n",
    "    reflection_prompt = (\n",
    "    f\"Based on the user query, the following code has been generated:\\n\"\n",
    "    \"user query: {query}\"\n",
    "    \"generated code: {answer}\"\n",
    "    \"the generated code has following problem:\"\n",
    "    \"problem: {feedback}\"\n",
    "    \"extract a short rule (one line) that usefull in the future.\"\n",
    "    \"for example, tell which points should consider to get more accurate code based on the user query.\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = \"llama3\",\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    lesson = llm.invoke([HumanMessage(content = reflection_prompt)]).content\n",
    "\n",
    "\n",
    "    memory_system.save_lesson(lesson)\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "00bc2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: AgentState):\n",
    "    if state[\"solved\"]:\n",
    "        return END \n",
    "    if state[\"attempt_count\"] > 3:\n",
    "        return END \n",
    "    return \"reflector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9ee248f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"generator\", code_generator_node)\n",
    "workflow.add_node(\"validator\", validator_node)\n",
    "workflow.add_node(\"reflector\", reflector_node)\n",
    "\n",
    "workflow.set_entry_point(\"generator\")\n",
    "workflow.add_edge(\"generator\", \"validator\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"validator\",\n",
    "    router, {\n",
    "        \"reflector\": \"reflector\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"reflector\", \"generator\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0730e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query: str):\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"answer\": \"\",\n",
    "        \"feedback\": \"\",\n",
    "        \"attempt_count\": 0,\n",
    "        \"solved\": False\n",
    "    }\n",
    "\n",
    "    final_state = app.invoke(initial_state)\n",
    "\n",
    "    print(\"\\n======= Final Result =======\")\n",
    "    print(f\"\\nSolved: {final_state.get('solved')}\")\n",
    "    print(f\"\\nAttempts: {final_state.get('attempt_count')}\")\n",
    "    print(f\"\\nLast feedback: {final_state.get('feedback')}\")\n",
    "\n",
    "    print(\"\\n======= Long Term Memory =======\")\n",
    "    lessons = memory_system.load_lessons()\n",
    "    for i, lesson in enumerate(lessons, 1):\n",
    "        print(f\"{i}. {lesson}\")\n",
    "\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "170e8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Number 0:\n",
      "\n",
      "To create an English teacher agent using LangGraph, you can follow these steps:\n",
      "\n",
      "1. Install the necessary dependencies:\n",
      "```\n",
      "pip install langgraph\n",
      "```\n",
      "2. Import the necessary libraries:\n",
      "```python\n",
      "import langgraph as lg\n",
      "from langgraph import Graph\n",
      "```\n",
      "3. Create a graph object:\n",
      "```python\n",
      "graph = Graph()\n",
      "```\n",
      "4. Add nodes to the graph representing different parts of speech:\n",
      "```python\n",
      "# Nodes for nouns, verbs, adjectives, and adverbs\n",
      "noun_node = lg.Node(\"Noun\")\n",
      "verb_node = lg.Node(\"Verb\")\n",
      "adjective_node = lg.Node(\"Adjective\")\n",
      "adverb_node = lg.Node(\"Adverb\")\n",
      "```\n",
      "5. Add edges between the nodes to represent grammatical relationships:\n",
      "```python\n",
      "# Edges for subject-verb agreement\n",
      "graph.add_edge(noun_node, verb_node)\n",
      "graph.add_edge(adjective_node, verb_node)\n",
      "graph.add_edge(adverb_node, verb_node)\n",
      "\n",
      "# Edges for object-verb agreement\n",
      "graph.add_edge(noun_node, verb_node)\n",
      "graph.add_edge(adjective_node, verb_node)\n",
      "graph.add_edge(adverb_node, verb_node)\n",
      "```\n",
      "6. Add nodes and edges to represent other grammatical structures:\n",
      "```python\n",
      "# Nodes for clauses and phrases\n",
      "clause_node = lg.Node(\"Clause\")\n",
      "phrase_node = lg.Node(\"Phrase\")\n",
      "\n",
      "# Edges for clause-phrase relationships\n",
      "graph.add_edge(clause_node, phrase_node)\n",
      "```\n",
      "7. Use the graph to analyze and generate sentences:\n",
      "```python\n",
      "# Analyze a sentence using the graph\n",
      "sentence = \"The dog chased the cat.\"\n",
      "tokens = sentence.split()\n",
      "for token in tokens:\n",
      "    node = lg.Node(token)\n",
      "    graph.add_node(node)\n",
      "\n",
      "# Generate a new sentence based on the analysis\n",
      "new_sentence = graph.generate_sentence()\n",
      "print(new_sentence)\n",
      "```\n",
      "This code will create a graph object, add nodes and edges to represent different parts of speech and grammatical structures, and use the graph to analyze and generate sentences. You can modify this code to suit your specific needs and expand it to include more advanced features such as parsing and generation of complex sentences.\n",
      "\n",
      "\n",
      "---Try number: 1 ---\n",
      "\n",
      "The code provided is a basic implementation of a graph-based language model using the LangGraph library. It includes the necessary steps to create a graph, add nodes and edges representing different parts of speech and grammatical structures, and use the graph to analyze and generate sentences. However, it does not include any advanced features such as parsing or generation of complex sentences.\n",
      "\n",
      "Therefore, I would give this code a score of 30 out of 100. The code is able to create a basic graph object and add nodes and edges representing different parts of speech and grammatical structures, but it does not demonstrate any advanced features such as parsing or generation of complex sentences.\n",
      "score: 30\n",
      "New lesson is saved in long term memory: I'm happy to help!\n",
      "\n",
      "Please provide the user query, generated code, and feedback, and I'll extract a short rule that can be useful for future reference.\n",
      "\n",
      "Format: Please provide the information in the following format:\n",
      "\n",
      "* User query: {query}\n",
      "* Generated code: {answer}\n",
      "* Feedback: {feedback}\n",
      "\n",
      "Example:\n",
      "User query: What is the weather like today?\n",
      "Generated code: The current weather is sunny with a high of 75Â°F.\n",
      "Feedback: The generated code is accurate, but it would be more helpful if it included the location.\n",
      "\n",
      "Once I have this information, I'll extract a short rule that can be useful for future reference.\n",
      "Code Number 1:\n",
      "\n",
      "Here is an improved version of the Python code for the task \"How to write an English teacher agent using langgraph?\":\n",
      "```python\n",
      "import langgraph as lg\n",
      "\n",
      "# Define the language model\n",
      "model = lg.LanguageModel(\"english\")\n",
      "\n",
      "# Load the pre-trained language model\n",
      "model.load_pretrained()\n",
      "\n",
      "# Define the teacher agent\n",
      "class EnglishTeacherAgent(lg.TeacherAgent):\n",
      "    def __init__(self, name):\n",
      "        super().__init__(name)\n",
      "        self.model = model\n",
      "\n",
      "    def get_response(self, input_text):\n",
      "        # Use the language model to generate a response\n",
      "        response = self.model.generate_response(input_text)\n",
      "        return response\n",
      "\n",
      "# Create an instance of the teacher agent\n",
      "agent = EnglishTeacherAgent(\"English Teacher\")\n",
      "\n",
      "# Test the agent's response\n",
      "print(agent.get_response(\"What is the capital of France?\"))\n",
      "```\n",
      "This code defines a `LanguageModel` object using the `langgraph` library, and then loads a pre-trained language model for English. It then defines a `TeacherAgent` class that inherits from the `lg.TeacherAgent` class, and overrides the `get_response()` method to use the loaded language model to generate responses. Finally, it creates an instance of the teacher agent and tests its response to a sample input text.\n",
      "\n",
      "This code has several improvements over the original version:\n",
      "\n",
      "* It uses the `langgraph` library to define the language model and load the pre-trained model, which makes it easier to use and more efficient.\n",
      "* It defines a custom `TeacherAgent` class that inherits from the `lg.TeacherAgent` class, which allows for more flexibility in defining the agent's behavior.\n",
      "* It uses the `generate_response()` method of the language model to generate responses, which is more efficient and accurate than using a simple regex pattern.\n",
      "* It includes proper documentation of the code, including the purpose of the code and any assumptions made.\n",
      "\n",
      "Overall, this improved version of the code is more efficient, accurate, and maintainable, which can lead to higher scores on your debugging assessment.\n",
      "\n",
      "\n",
      "---Try number: 2 ---\n",
      "    95\n",
      "score: 95\n",
      "Success! The code is highly corresponds to the user query.\n",
      "\n",
      "======= Final Result =======\n",
      "\n",
      "Solved: True\n",
      "\n",
      "Attempts: 2\n",
      "\n",
      "Last feedback: \n",
      "\n",
      "======= Long Term Memory =======\n"
     ]
    }
   ],
   "source": [
    "response = run_agent(\"How to write an english teacher agent using langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d431d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory is cleared. Now you can run from task 1.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"agent_memory10.json\"):\n",
    "    os.remove(\"agent_memory10.json\")\n",
    "    print(\"Memory is cleared. Now you can run from task 1.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
