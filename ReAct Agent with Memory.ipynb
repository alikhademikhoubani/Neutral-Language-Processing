{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f26d59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25c5b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc86379",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model = \"llama-3.3-70b-versatile\", groq_api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a036a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6386d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results = 2, tavily_api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ed9985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LangGraph - Overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/python/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents - including Klarna, Replit, Elastic, and more - LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.',\n",
       "  'score': 0.9405774},\n",
       " {'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of what’s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents.\\n It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents.',\n",
       "  'score': 0.9377661}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"What is langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55ec902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int)->int:\n",
    "    \"\"\"\n",
    "    Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int: output int\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f84e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0149735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "196d72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05bb4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_s = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1226326",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_s.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder_s.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder_s.add_edge(START, \"tool_calling_llm\")\n",
    "builder_s.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder_s.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "\n",
    "graph = builder_s.compile(checkpointer = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c73cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa1270f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query):\n",
    "    response = graph.invoke({\"messages\": query}, config = config)\n",
    "    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e20d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Khademi, it's nice to meet you. I'll make sure to remember your name this time. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"Hi, my name is khademi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10c57ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Khademi.\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"What is my name?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
