{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44060fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_classic.schema import HumanMessage\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3267c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55f1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_b64 = image_to_base64(\"im2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8f6723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21892\\1174598420.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llava\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e17907",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": (\n",
    "                \"You are an assistant tasked with summarizing tables for retrieval. \"\n",
    "                \"Give a summary optimized for embedding and retrieval.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{image_b64}\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7e5a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image displays a table with various columns, each containing numerical data. Here's a summary optimized for embedding and retrieval:\n",
      "\n",
      "- **Model**: The first column lists different models or versions of the model.\n",
      "- **Trainable**: This column indicates whether the model is trainable (1) or not (0).\n",
      "- **Wisdom**: The third column shows the number of wisdom points, which could be a measure of some sort of performance metric.\n",
      "- **Samsung**: The fourth column represents the number of Samsung devices.\n",
      "- **GPT3**: This column likely refers to GPT-3 models or versions, with corresponding numbers for each model.\n",
      "- **Lora**: Similar to GPT-3, this column seems to refer to Lora models or versions.\n",
      "- **Adaptor**: The seventh column shows the number of adaptors used in the context of these models.\n",
      "- **GPT2**: This column lists the number of GPT-2 models or versions.\n",
      "- **Lora2**: Similar to GPT-3 and Lora, this column likely refers to GPT-2 models or versions with corresponding numbers for each model.\n",
      "- **Adaptor2**: The ninth column shows the number of adaptors used in conjunction with GPT-2 models or versions.\n",
      "- **GPT4**: This column lists the number of GPT-4 models or versions.\n",
      "- **Lora4**: Similar to GPT-3 and Lora, this column likely refers to GPT-4 models or versions with corresponding numbers for each model.\n",
      "- **Adaptor4**: The eleventh column shows the number of adaptors used in conjunction with GPT-4 models or versions.\n",
      "\n",
      "The table is structured in a way that allows for easy retrieval and comparison of data across different models and versions, as well as the number of Samsung devices, wisdom points, and adaptors associated with each model. \n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([message])\n",
    "summary = response.content\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
